# -*- coding: utf-8 -*-
"""Feature Extraction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HcfMXvhqNJ75G6lqvXdaYBg9Yc5ooL8B

# **Feature Extraction**

Two separate sequential models are used for processing audio and visual inputs. There are hidden layer like Linear and ReLU Activation are used for both features.


Audio and visual features are processed independently.


Both audio and visual features are transformed into embeddings of size 300, making it easier to combine or compare them in later stages
"""

import torch.nn as nn

class FeatureExtractor(nn.Module):
    def __init__(self):
        super(FeatureExtractor, self).__init__()
        self.audio_fc = nn.Sequential(
            nn.Linear(40, 128),
            nn.ReLU(),
            nn.Linear(128, 300)
        )
        self.visual_fc = nn.Sequential(
            nn.Linear(512, 300),
            nn.ReLU(),
            nn.Linear(300, 300)
        )

    def forward(self, audio, visual):
        audio_features = self.audio_fc(audio)
        visual_features = self.visual_fc(visual)
        return audio_features, visual_features