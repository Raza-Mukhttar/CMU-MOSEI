# -*- coding: utf-8 -*-
"""Multimodel Emotion Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HcfMXvhqNJ75G6lqvXdaYBg9Yc5ooL8B

# **Multimodal Emotion Classification**

 This is combining three VAEGAN translators and a Multimodal Transformer. Each translator processes input features (audio, visual, text) with a latent representation of 128 dimensions, while the transformer fuses these outputs to predict one of six emotion classes.

 Both components are trained jointly using the Adam optimizer and CrossEntropyLoss, ensuring synchronized learning of feature translation and classification.

 The training loop runs for 10 epochs, tracking the average loss per epoch, followed by evaluation using a classification report to assess precision, recall, F1-score, and accuracy. This modular and scalable design allows for seamless adaptation to other multimodal tasks.


** FacedError:** Error faced because of dataloader which is not defined previously because mentioned issues
"""

# Initialize models
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
translators = [VAEGAN(300, 128, 300).to(device) for _ in range(3)]  # 3 translators
model = MultimodalTransformer(300, 128, 6).to(device)  # 6 emotion classes

# Optimizer and loss function
optimizer = torch.optim.Adam(
    list(model.parameters()) + [param for translator in translators for param in translator.parameters()],
    lr=1e-4
)
criterion = nn.CrossEntropyLoss()

# Training loop
epochs = 10
for epoch in range(epochs):
    train_loss = train_model(dataloader, model, translators, optimizer, criterion, device)
    print(f"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}")

# Evaluation
evaluate_model(dataloader, model, device)