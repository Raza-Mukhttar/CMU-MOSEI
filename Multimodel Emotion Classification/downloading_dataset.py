# -*- coding: utf-8 -*-
"""Dataset Preparation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HcfMXvhqNJ75G6lqvXdaYBg9Yc5ooL8B

# **Multimodal Emotion Recognition Using Cross-Modal Translation**

**Installing some mendatory libraries to access CMU-MOSEI dataset via SDK**
"""

!pip install multimodal-sdk
!pip install h5py
!pip install pandas

"""**Installing the CMU-MultimodalSDK to access the dataset from github**"""

!pip install multimodal-sdk --upgrade
!pip install git+https://github.com/CMU-MultiComp-Lab/CMU-MultimodalSDK.git

"""**Using mmsdk to downlaod dataset locally and save at the specified path /content/cmumosei**

Downloading high level features which include visual, audio and textual features
"""

!pip install mmsdk
from mmsdk import mmdatasdk

dataset = mmdatasdk.mmdataset(mmdatasdk.cmu_mosei.highlevel,'cmumosei/')

"""**Read avaiable modalities in downloaded dataset**"""

print("Available modalities:", dataset.keys())